{
    "name": "crawler",
    "version": "2.0.0",
    "description": "Crawler is a ready-to-use web spider that works with proxies, asynchrony, rate limit, configurable request pools, jQuery, and seamless HTTP/2 support.",
    "repository": {
        "type": "git",
        "url": "https://github.com/bda-research/node-crawler.git"
    },
    "exports": "./dist/index.js",
    "scripts": {
        "build": "tsc",
        "test": "mocha"
    },
    "engines": {
        "node": ">=18"
    },
    "type": "module",
    "keywords": [
        "javascript",
        "crawler",
        "spider",
        "scraper",
        "scraping",
        "jquery",
        "nodejs",
        "http",
		"https",
		"http2",
		"got",
        "request",
		"url",
		"network",
		"gzip"
    ],
    "license": "MIT",
    "dependencies": {
        "cheerio": "1.0.0-rc.12",
        "got": "^14.4.0",
        "hpagent": "^1.2.0",
        "http2-wrapper": "^2.2.1",
        "iconv-lite": "^0.6.3",
        "seenreq": "^3.0.0",
        "tslog": "^4.9.2"
    },
    "devDependencies": {
        "@eslint/js": "^9.4.0",
        "@types/got": "^9.6.12",
        "@types/node": "^20.14.2",
        "chai": "^5.1.1",
        "eslint": "~9.4.0",
        "globals": "^15.3.0",
        "mocha": "^10.4.0",
        "mocha-testdata": "^1.2.0",
        "nock": "^13.5.4",
        "sinon": "^17.0.1",
        "tough-cookie": "^4.1.4",
        "tsx": "^4.11.2",
        "typescript": "^5.4.5",
        "typescript-eslint": "8.0.0-alpha.27"
    },
    "mocha": {
        "files": [
            "test/**/*.js"
        ],
        "timeout": 15000,
        "exit": true
    }
}
